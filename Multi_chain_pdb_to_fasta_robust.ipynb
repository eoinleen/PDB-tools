{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1SPVlOBzP8nOILRVD1DtW-nefU0Kn_kk6",
      "authorship_tag": "ABX9TyNQK/AuYLnT6LIK6u6sVDUh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eoinleen/PDB-tools/blob/main/Multi_chain_pdb_to_fasta_robust.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0HIyWUaKB9X8",
        "outputId": "b5600ca3-16d2-4d84-9761-f133df6c00fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Enhanced PDB to FASTA Converter ===\n",
            "Input method: Direct Upload\n",
            "Chain selection: ALL\n",
            "\n",
            "Setting up file upload...\n",
            "Please upload your PDB files:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ef301101-696b-4afd-b431-86add5c2846d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ef301101-696b-4afd-b431-86add5c2846d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Elsa_C6_003.pdb to Elsa_C6_003.pdb\n",
            "Moved Elsa_C6_003.pdb to processing directory\n",
            "Using upload directory: /tmp/tmpmvx18w_g\n",
            "Processing 1 PDB files...\n",
            "Found chains ['A', 'B', 'C', 'D', 'E', 'F'] in Elsa_C6_003.pdb\n",
            "Processed Elsa_C6_003.pdb, chain A: 90 residues\n",
            "Processed Elsa_C6_003.pdb, chain B: 90 residues\n",
            "Processed Elsa_C6_003.pdb, chain C: 90 residues\n",
            "Processed Elsa_C6_003.pdb, chain D: 90 residues\n",
            "Processed Elsa_C6_003.pdb, chain E: 90 residues\n",
            "Processed Elsa_C6_003.pdb, chain F: 90 residues\n",
            "\n",
            "Created combined FASTA file: /tmp/tmpmvx18w_g/all_sequences.txt\n",
            "\n",
            "Processed 1 PDB files.\n",
            "\n",
            "‚úÖ Conversion completed successfully!\n",
            "\n",
            "Preparing files for download...\n",
            "Prepared 6_allchains.txt for download\n",
            "Prepared all_sequences.txt for download\n",
            "\n",
            "Attempting automatic download...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_68d460d6-322a-4d39-97de-b73d723367f1\", \"6_allchains.txt\", 611)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Initiated download for 6_allchains.txt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_19e1bf3d-daec-4c52-b880-b54856ffbade\", \"all_sequences.txt\", 611)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Initiated download for all_sequences.txt\n",
            "\n",
            "==================================================\n",
            "üìÅ DOWNLOAD OPTIONS:\n",
            "==================================================\n",
            "If files aren't in your Downloads folder, try these options:\n",
            "\n",
            "1. üìÇ MANUAL DOWNLOAD (Most Reliable):\n",
            "   - Look at the file browser panel on the left\n",
            "   - Navigate to: /content/fasta_output/\n",
            "   - Right-click each file ‚Üí Download\n",
            "\n",
            "2. üîÑ RE-RUN DOWNLOAD:\n",
            "   Run this code in a new cell:\n",
            "   ```python\n",
            "   from google.colab import files\n",
            "   files.download('/content/fasta_output/6_allchains.txt')\n",
            "   files.download('/content/fasta_output/all_sequences.txt')\n",
            "   ```\n",
            "\n",
            "3. üìã VIEW FILE CONTENTS:\n",
            "   Run this to see file contents (for copy/paste):\n",
            "   ```python\n",
            "   with open('/content/fasta_output/6_allchains.txt', 'r') as f:\n",
            "       print('=== 6_allchains.txt ===')\n",
            "       print(f.read())\n",
            "       print('\\n')\n",
            "   with open('/content/fasta_output/all_sequences.txt', 'r') as f:\n",
            "       print('=== all_sequences.txt ===')\n",
            "       print(f.read())\n",
            "       print('\\n')\n",
            "   ```\n",
            "\n",
            "4. üíæ SAVE TO GOOGLE DRIVE:\n",
            "   ```python\n",
            "   import shutil\n",
            "   drive_folder = '/content/drive/MyDrive/FASTA_Output/'\n",
            "   import os; os.makedirs(drive_folder, exist_ok=True)\n",
            "   shutil.copy('/content/fasta_output/6_allchains.txt', drive_folder)\n",
            "   shutil.copy('/content/fasta_output/all_sequences.txt', drive_folder)\n",
            "   ```\n",
            "\n",
            "üìå Files are temporarily saved in: /content/fasta_output/\n",
            "   (These will be deleted when the Colab session ends)\n",
            "\n",
            "Original temporary files cleaned up.\n"
          ]
        }
      ],
      "source": [
        "# Enhanced PDB to FASTA Converter for Google Colab\n",
        "# =================================================\n",
        "# This script extracts amino acid sequences from PDB files\n",
        "# and saves them in FASTA format. It supports both Google Drive\n",
        "# and direct file upload methods, with multi-chain extraction.\n",
        "#\n",
        "# Features:\n",
        "# - Two input methods: Google Drive path or direct upload\n",
        "# - Extracts sequences from specified chains or all chains\n",
        "# - Handles multiple filename patterns\n",
        "# - Outputs individual FASTA files per design\n",
        "# - Creates a combined 'all_sequences.txt' FASTA file\n",
        "# - Multi-chain support with chain-specific naming\n",
        "#\n",
        "# Requirements:\n",
        "# - Ensure Biopython is installed\n",
        "#\n",
        "# Usage:\n",
        "# - Choose input method (1 for Google Drive, 2 for upload)\n",
        "# - Set chain preferences (specific chains or 'ALL')\n",
        "# - Run the script in Google Colab\n",
        "# =================================================\n",
        "\n",
        "# ===== SETTINGS - EDIT THESE =====\n",
        "INPUT_METHOD = 2  # 1 = Google Drive, 2 = Direct Upload\n",
        "PDB_DIRECTORY = \"/content/drive/MyDrive/PDB-files/\"  # Only used if INPUT_METHOD = 1\n",
        "CHAIN_IDS = \"ALL\"  # Options: \"A\", \"A,B\", \"ALL\" for all chains\n",
        "# ================================\n",
        "\n",
        "# Install required packages\n",
        "%pip install -q biopython\n",
        "\n",
        "# Import necessary libraries\n",
        "import os\n",
        "import re\n",
        "import glob\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "import tempfile\n",
        "import shutil\n",
        "\n",
        "# Dictionary to convert three-letter amino acid codes to one-letter codes\n",
        "three_to_one = {\n",
        "    'ALA': 'A', 'CYS': 'C', 'ASP': 'D', 'GLU': 'E',\n",
        "    'PHE': 'F', 'GLY': 'G', 'HIS': 'H', 'ILE': 'I',\n",
        "    'LYS': 'K', 'LEU': 'L', 'MET': 'M', 'ASN': 'N',\n",
        "    'PRO': 'P', 'GLN': 'Q', 'ARG': 'R', 'SER': 'S',\n",
        "    'THR': 'T', 'VAL': 'V', 'TRP': 'W', 'TYR': 'Y'\n",
        "}\n",
        "\n",
        "def get_all_chains_from_pdb(pdb_file):\n",
        "    \"\"\"Get all unique chain IDs from a PDB file.\"\"\"\n",
        "    chains = set()\n",
        "    with open(pdb_file, 'r', encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            if line.startswith('ATOM'):\n",
        "                chain_id = line[21]\n",
        "                if chain_id.strip():  # Only add non-empty chain IDs\n",
        "                    chains.add(chain_id)\n",
        "    return sorted(list(chains))\n",
        "\n",
        "def extract_sequence_from_pdb(pdb_file, chain_id):\n",
        "    \"\"\"Extract the amino acid sequence from a specified chain in a PDB file.\"\"\"\n",
        "    sequence = \"\"\n",
        "    seen_residues = set()\n",
        "\n",
        "    with open(pdb_file, 'r', encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            if line.startswith('ATOM') and line[21] == chain_id:\n",
        "                res_name = line[17:20].strip()\n",
        "                res_num = line[22:26].strip()\n",
        "\n",
        "                if res_num not in seen_residues:\n",
        "                    if res_name in three_to_one:\n",
        "                        sequence += three_to_one[res_name]\n",
        "                    seen_residues.add(res_num)\n",
        "\n",
        "    return sequence\n",
        "\n",
        "def parse_design_number(filename):\n",
        "    \"\"\"Extracts the most relevant design number from the filename.\"\"\"\n",
        "    match = re.search(r'dldesign_(\\d+)', filename)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "\n",
        "    match = re.search(r'(\\d+)_bind', filename)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "\n",
        "    match = re.findall(r'\\d+', filename)\n",
        "    if match:\n",
        "        return max(match, key=int)  # Get the largest number as fallback\n",
        "\n",
        "    return os.path.splitext(filename)[0]\n",
        "\n",
        "def parse_sequence_number(filename):\n",
        "    \"\"\"Extracts sequence-related numbers if present.\"\"\"\n",
        "    match = re.search(r'_bind_(\\d+)', filename)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "\n",
        "    match = re.search(r'mpnn(\\d+)_model(\\d+)', filename)\n",
        "    if match:\n",
        "        return f\"mpnn{match.group(1)}_model{match.group(2)}\"\n",
        "\n",
        "    return \"\"\n",
        "\n",
        "def setup_upload_directory():\n",
        "    \"\"\"Create a temporary directory and handle file uploads.\"\"\"\n",
        "    print(\"Please upload your PDB files:\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if not uploaded:\n",
        "        print(\"No files uploaded.\")\n",
        "        return None\n",
        "\n",
        "    # Create temporary directory\n",
        "    temp_dir = tempfile.mkdtemp()\n",
        "\n",
        "    # Move uploaded files to temp directory\n",
        "    for filename in uploaded.keys():\n",
        "        if filename.endswith('.pdb'):\n",
        "            src_path = os.path.join('/content', filename)\n",
        "            dst_path = os.path.join(temp_dir, filename)\n",
        "            shutil.move(src_path, dst_path)\n",
        "            print(f\"Moved {filename} to processing directory\")\n",
        "        else:\n",
        "            print(f\"Skipping {filename} (not a PDB file)\")\n",
        "\n",
        "    return temp_dir\n",
        "\n",
        "def parse_chain_ids(chain_input):\n",
        "    \"\"\"Parse the chain ID input string.\"\"\"\n",
        "    if chain_input.upper() == \"ALL\":\n",
        "        return \"ALL\"\n",
        "    else:\n",
        "        # Split by comma and clean up\n",
        "        chains = [chain.strip().upper() for chain in chain_input.split(',')]\n",
        "        return [chain for chain in chains if chain]  # Remove empty strings\n",
        "\n",
        "def convert_pdb_to_fasta(pdb_dir, chain_ids):\n",
        "    \"\"\"Convert all PDB files in the directory to FASTA format.\"\"\"\n",
        "    if not os.path.isdir(pdb_dir):\n",
        "        print(f\"Error: Directory not found: {pdb_dir}\")\n",
        "        return False\n",
        "\n",
        "    pdb_files = glob.glob(os.path.join(pdb_dir, \"*.pdb\"))\n",
        "    if not pdb_files:\n",
        "        print(f\"No PDB files found in {pdb_dir}\")\n",
        "        return False\n",
        "\n",
        "    print(f\"Processing {len(pdb_files)} PDB files...\")\n",
        "    all_fasta_entries = []\n",
        "    processed_count = 0\n",
        "\n",
        "    for pdb_file in pdb_files:\n",
        "        filename = os.path.basename(pdb_file)\n",
        "        design_num = parse_design_number(filename)\n",
        "        seq_num = parse_sequence_number(filename)\n",
        "\n",
        "        # Determine which chains to process\n",
        "        if chain_ids == \"ALL\":\n",
        "            chains_to_process = get_all_chains_from_pdb(pdb_file)\n",
        "            print(f\"Found chains {chains_to_process} in {filename}\")\n",
        "        else:\n",
        "            chains_to_process = chain_ids\n",
        "\n",
        "        file_fasta_entries = []\n",
        "\n",
        "        for chain_id in chains_to_process:\n",
        "            sequence = extract_sequence_from_pdb(pdb_file, chain_id)\n",
        "\n",
        "            if not sequence:\n",
        "                print(f\"Warning: No sequence found for chain {chain_id} in {filename}\")\n",
        "                continue\n",
        "\n",
        "            # Create header with chain information\n",
        "            if len(chains_to_process) > 1:\n",
        "                header = f\">{design_num}_{seq_num}_chain{chain_id}\" if seq_num else f\">{design_num}_chain{chain_id}\"\n",
        "            else:\n",
        "                header = f\">{design_num}_{seq_num}\" if seq_num else f\">{design_num}\"\n",
        "\n",
        "            # Format sequence with line breaks every 60 characters\n",
        "            formatted_sequence = \"\\n\".join([sequence[i:i+60] for i in range(0, len(sequence), 60)])\n",
        "            fasta_entry = header + \"\\n\" + formatted_sequence\n",
        "\n",
        "            file_fasta_entries.append(fasta_entry)\n",
        "            all_fasta_entries.append(fasta_entry)\n",
        "\n",
        "            print(f\"Processed {filename}, chain {chain_id}: {len(sequence)} residues\")\n",
        "\n",
        "        if file_fasta_entries:\n",
        "            # Save individual file\n",
        "            if len(chains_to_process) > 1:\n",
        "                output_file = os.path.join(pdb_dir, f\"{design_num}_{seq_num}_allchains.txt\" if seq_num else f\"{design_num}_allchains.txt\")\n",
        "            else:\n",
        "                output_file = os.path.join(pdb_dir, f\"{design_num}_{seq_num}.txt\" if seq_num else f\"{design_num}.txt\")\n",
        "\n",
        "            with open(output_file, 'w', encoding=\"utf-8\") as f:\n",
        "                f.write(\"\\n\".join(file_fasta_entries))\n",
        "\n",
        "            processed_count += 1\n",
        "\n",
        "    if processed_count > 0:\n",
        "        all_sequences_file = os.path.join(pdb_dir, \"all_sequences.txt\")\n",
        "        with open(all_sequences_file, 'w', encoding=\"utf-8\") as f:\n",
        "            f.write(\"\\n\".join(all_fasta_entries))\n",
        "        print(f\"\\nCreated combined FASTA file: {all_sequences_file}\")\n",
        "\n",
        "    print(f\"\\nProcessed {processed_count} PDB files.\")\n",
        "    return True, all_fasta_entries if processed_count > 0 else []\n",
        "\n",
        "# Main execution\n",
        "print(\"=== Enhanced PDB to FASTA Converter ===\")\n",
        "print(f\"Input method: {'Google Drive' if INPUT_METHOD == 1 else 'Direct Upload'}\")\n",
        "print(f\"Chain selection: {CHAIN_IDS}\")\n",
        "\n",
        "# Parse chain IDs\n",
        "chains = parse_chain_ids(CHAIN_IDS)\n",
        "\n",
        "# Setup input directory based on method\n",
        "if INPUT_METHOD == 1:\n",
        "    # Mount Google Drive\n",
        "    print(\"\\nMounting Google Drive...\")\n",
        "    drive.mount('/content/drive')\n",
        "    pdb_directory = PDB_DIRECTORY\n",
        "    print(f\"Using Google Drive directory: {pdb_directory}\")\n",
        "\n",
        "elif INPUT_METHOD == 2:\n",
        "    # Handle file upload\n",
        "    print(\"\\nSetting up file upload...\")\n",
        "    pdb_directory = setup_upload_directory()\n",
        "    if pdb_directory is None:\n",
        "        print(\"Upload failed. Exiting.\")\n",
        "        exit()\n",
        "    print(f\"Using upload directory: {pdb_directory}\")\n",
        "\n",
        "else:\n",
        "    print(\"Invalid INPUT_METHOD. Use 1 for Google Drive or 2 for Direct Upload.\")\n",
        "    exit()\n",
        "\n",
        "# Run the conversion\n",
        "conversion_result = convert_pdb_to_fasta(pdb_directory, chains)\n",
        "if conversion_result[0]:  # If conversion was successful\n",
        "    print(\"\\n‚úÖ Conversion completed successfully!\")\n",
        "\n",
        "    if INPUT_METHOD == 2:\n",
        "        print(\"\\nPreparing files for download...\")\n",
        "\n",
        "        # Copy files to /content/ directory for reliable downloading\n",
        "        download_dir = \"/content/fasta_output\"\n",
        "        os.makedirs(download_dir, exist_ok=True)\n",
        "\n",
        "        # Copy all FASTA files to download directory\n",
        "        fasta_files = glob.glob(os.path.join(pdb_directory, \"*.txt\"))\n",
        "        copied_files = []\n",
        "\n",
        "        for fasta_file in fasta_files:\n",
        "            filename = os.path.basename(fasta_file)\n",
        "            dest_path = os.path.join(download_dir, filename)\n",
        "            shutil.copy2(fasta_file, dest_path)\n",
        "            copied_files.append(dest_path)\n",
        "            print(f\"Prepared {filename} for download\")\n",
        "\n",
        "        # Try automatic download first\n",
        "        print(\"\\nAttempting automatic download...\")\n",
        "        download_success = []\n",
        "        for file_path in copied_files:\n",
        "            try:\n",
        "                files.download(file_path)\n",
        "                download_success.append(True)\n",
        "                print(f\"‚úì Initiated download for {os.path.basename(file_path)}\")\n",
        "            except Exception as e:\n",
        "                download_success.append(False)\n",
        "                print(f\"‚úó Error downloading {os.path.basename(file_path)}: {e}\")\n",
        "\n",
        "        # If downloads seem to fail, provide manual options\n",
        "        if not all(download_success):\n",
        "            print(\"\\n‚ö†Ô∏è  Some automatic downloads may have failed.\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"üìÅ DOWNLOAD OPTIONS:\")\n",
        "        print(\"=\"*50)\n",
        "        print(\"If files aren't in your Downloads folder, try these options:\")\n",
        "        print(\"\\n1. üìÇ MANUAL DOWNLOAD (Most Reliable):\")\n",
        "        print(\"   - Look at the file browser panel on the left\")\n",
        "        print(\"   - Navigate to: /content/fasta_output/\")\n",
        "        print(\"   - Right-click each file ‚Üí Download\")\n",
        "\n",
        "        print(\"\\n2. üîÑ RE-RUN DOWNLOAD:\")\n",
        "        print(\"   Run this code in a new cell:\")\n",
        "        print(\"   ```python\")\n",
        "        print(\"   from google.colab import files\")\n",
        "        for file_path in copied_files:\n",
        "            print(f\"   files.download('/content/fasta_output/{os.path.basename(file_path)}')\")\n",
        "        print(\"   ```\")\n",
        "\n",
        "        print(\"\\n3. üìã VIEW FILE CONTENTS:\")\n",
        "        print(\"   Run this to see file contents (for copy/paste):\")\n",
        "        print(\"   ```python\")\n",
        "        for file_path in copied_files:\n",
        "            print(f\"   with open('/content/fasta_output/{os.path.basename(file_path)}', 'r') as f:\")\n",
        "            print(f\"       print('=== {os.path.basename(file_path)} ===')\")\n",
        "            print(f\"       print(f.read())\")\n",
        "            print(f\"       print('\\\\n')\")\n",
        "        print(\"   ```\")\n",
        "\n",
        "        print(\"\\n4. üíæ SAVE TO GOOGLE DRIVE:\")\n",
        "        print(\"   ```python\")\n",
        "        print(\"   import shutil\")\n",
        "        print(\"   drive_folder = '/content/drive/MyDrive/FASTA_Output/'\")\n",
        "        print(\"   import os; os.makedirs(drive_folder, exist_ok=True)\")\n",
        "        for file_path in copied_files:\n",
        "            print(f\"   shutil.copy('/content/fasta_output/{os.path.basename(file_path)}', drive_folder)\")\n",
        "        print(\"   ```\")\n",
        "\n",
        "        # Don't clean up immediately so users can access files\n",
        "        print(f\"\\nüìå Files are temporarily saved in: /content/fasta_output/\")\n",
        "        print(\"   (These will be deleted when the Colab session ends)\")\n",
        "\n",
        "        # Clean up original temp directory but keep download directory\n",
        "        shutil.rmtree(pdb_directory)\n",
        "        print(\"\\nOriginal temporary files cleaned up.\")\n",
        "else:\n",
        "    print(\"\\n‚ùå Conversion failed.\")"
      ]
    }
  ]
}